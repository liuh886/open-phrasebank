{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrasebank from PDF\n",
    "\n",
    "This notebook has the purpose of extracting the most common phrases from the training data.\n",
    "\n",
    "E.g. a academic phrasebank from a poupular [scientific writing guidebooks](http://www.phrasebank.manchester.ac.uk/), or a high level scientific journal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from openphrasebank import extract_text_from_pdf, clean_text\n",
    "\n",
    "pdf_path = r\"../../data/Academic_Phrasebank.pdf\"\n",
    "\n",
    "# skip the cover and the last two page\n",
    "text = extract_text_from_pdf(pdf_path, skip_first=6, skip_last=2)\n",
    "cleaned_text = clean_text(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Extract the phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from openphrasebank import extract_verb_phrases, extract_expanded_noun_phrases, is_valid_phrase\n",
    "# Using English language pre-trained model from spaCy, visit for models in other language https://spacy.io/models\n",
    "#! python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(cleaned_text)\n",
    "# match with the verb and noun phrases patterns\n",
    "verb_phrases = extract_verb_phrases(doc)\n",
    "expanded_noun_phrases = extract_expanded_noun_phrases(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Filter and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine lists and remove duplicates\n",
    "combined_phrases = set(expanded_noun_phrases + verb_phrases)\n",
    "\n",
    "# sort\n",
    "sorted_phrases = sorted({phrase for phrase in combined_phrases if 1 < len(phrase.split(' ')) < 5 and len(phrase) > 2 and is_valid_phrase(phrase)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3: Save the data\n",
    "import re\n",
    "# Write the sorted phrases to a Markdown file\n",
    "with open('../../phrasebanks/academic_phrasebank.md', 'w') as file:\n",
    "    for phrase in sorted_phrases:\n",
    "        cleaned_phrase = re.sub(r'\\n*', '', phrase)\n",
    "        file.write(cleaned_phrase + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
